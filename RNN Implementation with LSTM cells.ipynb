{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, json, random\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    data_path=\"Data/mfcc_samples.json\",\n",
    "    save_dir=\"Model/\",\n",
    "    # Model hyper parameter\n",
    "    hidden_size = 64,\n",
    "    input_size = 32,\n",
    "    num_classes = 5,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.005,\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "args.input_size += args.hidden_size\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(args.data_path, 'r')\n",
    "samples = json.load(f)\n",
    "f.close()\n",
    "longest = 0\n",
    "for num in samples.keys():\n",
    "    for ind, mfcc in enumerate(samples[num]):\n",
    "        longest = max(longest, len(mfcc))\n",
    "        samples[num][ind] = np.asarray(mfcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, test_samples = [], []\n",
    "train_size = 0.8\n",
    "for num in samples:\n",
    "    mfccs = samples[num]\n",
    "    random.shuffle(mfccs)\n",
    "    size = len(mfccs)\n",
    "    train = mfccs[:int(size * train_size)]\n",
    "    train = [(vec, num) for vec in train]\n",
    "    test = mfccs[int(size * train_size):]\n",
    "    test = [(vec, num) for vec in test]\n",
    "    train_samples.extend(train)\n",
    "    test_samples.extend(test)\n",
    "\n",
    "random.shuffle(train_samples)\n",
    "random.shuffle(test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batched = {}\n",
    "for sample, target in train_samples:\n",
    "    length = sample.shape[0]\n",
    "    if length in train_batched:\n",
    "        train_batched[length].append((sample, target))\n",
    "    else:\n",
    "        train_batched[length] = [(sample, target)]\n",
    "\n",
    "train_batched = [lst for num, lst in train_batched.items()]\n",
    "\n",
    "test_batched = {}\n",
    "for sample, target in test_samples:\n",
    "    length = sample.shape[0]\n",
    "    if length in test_batched:\n",
    "        test_batched[length].append((sample, target))\n",
    "    else:\n",
    "        test_batched[length] = [(sample, target)]\n",
    "        \n",
    "test_batched = [lst for num, lst in test_batched.items()]\n",
    "\n",
    "for ind, lst in enumerate(train_batched):\n",
    "    arr = np.array([np.array(ls) for ls, num in lst])\n",
    "    targ = np.array([num for ls, num in lst])\n",
    "    train_batched[ind] = (arr, targ)\n",
    "\n",
    "for ind, lst in enumerate(test_batched):\n",
    "    arr = np.array([np.array(ls) for ls, num in lst])\n",
    "    targ = np.array([num for ls, num in lst])\n",
    "    test_batched[ind] = (arr, targ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Weights\n",
    "\n",
    "wf = np.random.randn(args.input_size, args.hidden_size) / np.sqrt(args.input_size / 2)\n",
    "wi = np.random.randn(args.input_size, args.hidden_size) / np.sqrt(args.input_size / 2)\n",
    "wc = np.random.randn(args.input_size, args.hidden_size) / np.sqrt(args.input_size / 2)\n",
    "wo = np.random.randn(args.input_size, args.hidden_size) / np.sqrt(args.input_size / 2)\n",
    "wy = np.random.randn(args.hidden_size, args.num_classes) / np.sqrt(args.hidden_size / 2)\n",
    "\n",
    "bf = np.zeros(args.hidden_size)\n",
    "bi = np.zeros(args.hidden_size)\n",
    "bc = np.zeros(args.hidden_size)\n",
    "bo = np.zeros(args.hidden_size)\n",
    "by = np.zeros(args.num_classes)\n",
    "\n",
    "# Initialize delta values\n",
    "\n",
    "dwf = np.zeros_like(wf)\n",
    "dwi = np.zeros_like(wi)\n",
    "dwc = np.zeros_like(wc)\n",
    "dwo = np.zeros_like(wo)\n",
    "dwy = np.zeros_like(wy)\n",
    "\n",
    "dbf = np.zeros_like(bf)\n",
    "dbi = np.zeros_like(bi)\n",
    "dbc = np.zeros_like(bc)\n",
    "dbo = np.zeros_like(bo)\n",
    "dby = np.zeros_like(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(arr):\n",
    "    c = np.clip(arr, -700, 700) # float64 maximum expotentiable value\n",
    "    e = np.exp(c)\n",
    "    return e / np.sum(e, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy(out, label):\n",
    "    entropy = label * np.log(out + 1e-6) # to prevent log value overflow\n",
    "    return -np.sum(entropy, axis=1, keepdims=True)\n",
    "\n",
    "def sigmoid(arr):\n",
    "    c = np.clip(arr, -700, 700)\n",
    "    return 1 / (1 + np.exp(-c))\n",
    "\n",
    "def deriv_sigmoid(out):\n",
    "    return out * (1 - out)\n",
    "\n",
    "def tanh(arr):\n",
    "    c = np.clip(arr, -350, 350)\n",
    "    return 2 / (1 + np.exp(-2 * c)) - 1\n",
    "\n",
    "def deriv_tanh(out):\n",
    "    return 1 - np.square(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Cell(input_val):\n",
    "    batch_num = input_val.shape[1]\n",
    "    caches = []\n",
    "    states = []\n",
    "    states.append([np.zeros([batch_num, args.hidden_size]), np.zeros([batch_num, args.hidden_size])])\n",
    "    for x in input_val:\n",
    "        c_prev, h_prev = states[-1]\n",
    "        x = np.column_stack([x, h_prev])\n",
    "        \n",
    "        hf = sigmoid(np.matmul(x, wf) + bf)\n",
    "        hi = sigmoid(np.matmul(x, wi) + bi)\n",
    "        ho = sigmoid(np.matmul(x, wo) + bo)\n",
    "        hc = tanh(np.matmul(x, wc) + bc)\n",
    "    \n",
    "        c = hf * c_prev + hi * hc\n",
    "        h = ho * tanh(c)\n",
    "        \n",
    "        states.append([c, h])\n",
    "        caches.append([x, hf, hi, ho, hc])\n",
    "        \n",
    "    return caches, states\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample):\n",
    "    \n",
    "    input_val = np.transpose(sample, [1, 0, 2])\n",
    "    \n",
    "    caches, states = LSTM_Cell(input_val)\n",
    "    c, h = states[-1]\n",
    "    \n",
    "    pred = softmax(np.dot(h, wy) + by)\n",
    "    label = np.argmax(pred)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Training Loss 1.63396\n",
      "Training Accuracy 19.577 %\n",
      "Iteration 1\n",
      "Training Loss 1.61686\n",
      "Training Accuracy 18.933 %\n",
      "Iteration 2\n",
      "Training Loss 1.61676\n",
      "Training Accuracy 19.081 %\n",
      "Iteration 3\n",
      "Training Loss 1.6171\n",
      "Training Accuracy 19.296 %\n",
      "Iteration 4\n",
      "Training Loss 1.61791\n",
      "Training Accuracy 19.379 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-367-a7be7c19412a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdhc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdhc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mderiv_tanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mdwf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdhf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mdbf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mdXf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(args.num_epochs):\n",
    "    loss, correct = 0, 0\n",
    "    size = len(train_samples)\n",
    "    for sample, target in train_batched:\n",
    "        X = sample\n",
    "        Y = np.zeros((target.shape[0], args.num_classes))\n",
    "        target = [int(t)-1 for t in target]\n",
    "        for ind, num in enumerate(target):\n",
    "            Y[ind][num] = 1\n",
    "        Xt = np.transpose(X, [1, 0, 2])\n",
    "\n",
    "        caches, states = LSTM_Cell(Xt)\n",
    "        c, h = states[-1]\n",
    "        out = np.dot(h, wy) + by\n",
    "        pred = softmax(out)\n",
    "        loss += np.sum(cross_entropy(pred, Y))\n",
    "        predicted = np.argmax(pred, axis=1)\n",
    "                \n",
    "        # calculate accuracy\n",
    "        correct += np.sum(predicted == target)\n",
    "        \n",
    "\n",
    "        # Backpropagation Through Time\n",
    "        dout = pred - Y\n",
    "        dwy = np.dot(h.T, dout)\n",
    "        dby = np.sum(dout, axis=0)\n",
    "\n",
    "\n",
    "        dc_next = np.zeros_like(c)\n",
    "        dh_next = np.zeros_like(h)\n",
    "\n",
    "        for t in range(Xt.shape[0]):\n",
    "            c, h = states[-t-1]\n",
    "            c_prev, h_prev = states[-t-2]\n",
    "\n",
    "            x, hf, hi, ho, hc = caches[-t-1]\n",
    "\n",
    "            tc = tanh(c)\n",
    "            dh = np.dot(dout, wy.T) + dh_next\n",
    "\n",
    "            dc = dh * ho * deriv_tanh(tc)\n",
    "            dc = dc + dc_next\n",
    "\n",
    "            dho = dh * tc \n",
    "            dho = dho * deriv_sigmoid(ho)\n",
    "\n",
    "            dhf = dc * c_prev \n",
    "            dhf = dhf * deriv_sigmoid(hf)\n",
    "\n",
    "            dhi = dc * hc \n",
    "            dhi = dhi * deriv_sigmoid(hi)\n",
    "\n",
    "            dhc = dc * hi \n",
    "            dhc = dhc * deriv_tanh(hc)\n",
    "\n",
    "            dwf += np.dot(x.T, dhf)\n",
    "            dbf += np.sum(dhf, axis=0)\n",
    "            dXf = np.dot(dhf, wf.T)\n",
    "\n",
    "            dwi += np.dot(x.T, dhi)\n",
    "            dbi += np.sum(dhi, axis=0)\n",
    "            dXi = np.dot(dhi, wi.T)\n",
    "\n",
    "            dwo += np.dot(x.T, dho)\n",
    "            dbo += np.sum(dho, axis=0)\n",
    "            dXo = np.dot(dho, wo.T)\n",
    "\n",
    "            dwc += np.dot(x.T, dhc)\n",
    "            dbc += np.sum(dhc, axis=0)\n",
    "            dXc = np.dot(dhc, wc.T)\n",
    "\n",
    "            dX = dXf + dXi + dXo + dXc\n",
    "\n",
    "            dc_next = hf * dc\n",
    "            dh_next = dX[:, -args.hidden_size:]\n",
    "\n",
    "        # Update weights        \n",
    "        wf -= args.learning_rate * dwf\n",
    "        wi -= args.learning_rate * dwi\n",
    "        wc -= args.learning_rate * dwc\n",
    "        wo -= args.learning_rate * dwo\n",
    "        wy -= args.learning_rate * dwy\n",
    "\n",
    "        bf -= args.learning_rate * dbf\n",
    "        bi -= args.learning_rate * dbi\n",
    "        bc -= args.learning_rate * dbc\n",
    "        bo -= args.learning_rate * dbo\n",
    "        by -= args.learning_rate * dby\n",
    "\n",
    "        # Initialize delta values\n",
    "        dwf *= 0\n",
    "        dwi *= 0\n",
    "        dwc *= 0\n",
    "        dwo *= 0\n",
    "        dwy *= 0\n",
    "\n",
    "        dbf *= 0\n",
    "        dbi *= 0\n",
    "        dbc *= 0\n",
    "        dbo *= 0\n",
    "        dby *= 0\n",
    "\n",
    "\n",
    "\n",
    "    print('Iteration', i)\n",
    "    print('Training Loss', round(loss / size, 5))\n",
    "    print('Training Accuracy', round(correct / size * 100, 3), '%')\n",
    "    \"\"\"\n",
    "    loss, correct = 0, 0\n",
    "    size = len(test_samples)\n",
    "    for sample, target in test_samples:\n",
    "        X = np.expand_dims(sample, axis=0)\n",
    "        Y = np.zeros((args.num_classes,))\n",
    "        target = int(target) - 1\n",
    "        Y[target] = 1\n",
    "        Xt = np.transpose(X, [1, 0, 2])\n",
    "\n",
    "        caches, states = LSTM_Cell(Xt)\n",
    "        c, h = states[-1]\n",
    "\n",
    "        out = np.dot(h, wy) + by\n",
    "        pred = softmax(out)\n",
    "        loss += np.sum(cross_entropy(pred, Y))\n",
    "        predicted = np.argmax(pred)\n",
    "        \n",
    "    print('Validation Loss', round(loss / size, 5))\n",
    "    print('Validation Accuracy', round(correct / size * 100, 3), '%')\n",
    "    print('----------')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

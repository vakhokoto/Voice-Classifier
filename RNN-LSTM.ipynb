{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 32\n",
    "HIDDEN = 64\n",
    "OUTPUT = 5\n",
    "\n",
    "INPUT += HIDDEN\n",
    "\n",
    "ALPHA = 0.01\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "ITER_NUM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join('Data', 'mfcc_samples.json')\n",
    "f = open(data_path, 'r')\n",
    "samples = json.load(f)\n",
    "f.close()\n",
    "longest = 0\n",
    "for num in samples.keys():\n",
    "    for ind, mfcc in enumerate(samples[num]):\n",
    "        longest = max(longest, len(mfcc))\n",
    "        samples[num][ind] = np.asarray(mfcc)\n",
    "\n",
    "dim = samples['1'][0].shape[1]\n",
    "\n",
    "for num in samples.keys():\n",
    "    for ind, mfcc in enumerate(samples[num]):\n",
    "        length = len(mfcc)\n",
    "        to_pad = np.zeros((longest-length, dim))\n",
    "        samples[num][ind] = (np.vstack((mfcc, to_pad)), length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples['1'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [] # to plot learning curve of cross entropy\n",
    "\n",
    "wf = np.random.randn(INPUT, HIDDEN) / np.sqrt(INPUT / 2)\n",
    "wi = np.random.randn(INPUT, HIDDEN) / np.sqrt(INPUT / 2)\n",
    "wc = np.random.randn(INPUT, HIDDEN) / np.sqrt(INPUT / 2)\n",
    "wo = np.random.randn(INPUT, HIDDEN) / np.sqrt(INPUT / 2)\n",
    "wy = np.random.randn(HIDDEN, OUTPUT) / np.sqrt(HIDDEN / 2)\n",
    "\n",
    "bf = np.zeros(HIDDEN)\n",
    "bi = np.zeros(HIDDEN)\n",
    "bc = np.zeros(HIDDEN)\n",
    "bo = np.zeros(HIDDEN)\n",
    "by = np.zeros(OUTPUT)\n",
    "\n",
    "dwf = np.zeros_like(wf)\n",
    "dwi = np.zeros_like(wi)\n",
    "dwc = np.zeros_like(wc)\n",
    "dwo = np.zeros_like(wo)\n",
    "dwy = np.zeros_like(wy)\n",
    "\n",
    "dbf = np.zeros_like(bf)\n",
    "dbi = np.zeros_like(bi)\n",
    "dbc = np.zeros_like(bc)\n",
    "dbo = np.zeros_like(bo)\n",
    "dby = np.zeros_like(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(arr):\n",
    "    c = np.clip(arr, -700, 700) # float64 maximum expotentiable value\n",
    "    e = np.exp(c)\n",
    "    return e / np.sum(e, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy(out, label):\n",
    "    entropy = label * np.log(out + 1e-6) # to prevent log value overflow\n",
    "    return -np.sum(entropy, axis=1, keepdims=True)\n",
    "\n",
    "def sigmoid(arr):\n",
    "    c = np.clip(arr, -700, 700)\n",
    "    return 1 / (1 + np.exp(-c))\n",
    "\n",
    "def deriv_sigmoid(out):\n",
    "    return out * (1 - out)\n",
    "\n",
    "def tanh(arr):\n",
    "    c = np.clip(arr, -350, 350)\n",
    "    return 2 / (1 + np.exp(-2 * c)) - 1\n",
    "\n",
    "def deriv_tanh(out):\n",
    "    return 1 - np.square(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Cell(input_val):\n",
    "    batch_num = input_val.shape[1]\n",
    "    \n",
    "    caches = []\n",
    "    states = []\n",
    "    states.append([np.zeros([batch_num, HIDDEN]), np.zeros([batch_num, HIDDEN])])\n",
    "    \n",
    "    for x in input_val:\n",
    "        c_prev, h_prev = states[-1]\n",
    "    \n",
    "        x = np.column_stack([x, h_prev])\n",
    "        hf = sigmoid(np.dot(x, wf) + bf)\n",
    "        hi = sigmoid(np.dot(x, wi) + bi)\n",
    "        ho = sigmoid(np.dot(x, wo) + bo)\n",
    "        hc = tanh(np.dot(x, wc) + bc)\n",
    "    \n",
    "        c = hf * c_prev + hi * hc\n",
    "        h = ho * tanh(c)\n",
    "    \n",
    "        states.append([c, h])\n",
    "        caches.append([x, hf, hi, ho, hc])\n",
    "        \n",
    "    return caches, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    input_val = np.reshape(img, [28, 1, 28])\n",
    "    \n",
    "    caches, states = LSTM_Cell(input_val)\n",
    "    c, h = states[-1]\n",
    "    \n",
    "    pred = softmax(np.dot(h, wy) + by)\n",
    "    label = np.argmax(pred)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(64, 28, 28), dtype=float64)\n",
      "tf.Tensor(\n",
      "[0 7 4 9 7 8 3 2 1 1 8 3 6 1 0 3 1 0 0 1 7 2 7 3 0 4 6 5 2 6 4 7 1 8 9 9 3\n",
      " 0 7 1 0 2 0 3 5 4 6 5 8 6 3 7 5 8 0 9 1 0 3 1 2 2 3 3], shape=(64,), dtype=uint8)\n",
      "(28, 64, 28)\n"
     ]
    }
   ],
   "source": [
    "for i in range(ITER_NUM+1):\n",
    "    X, Y = iterator.get_next()\n",
    "#     print(X)\n",
    "#     print(Y)\n",
    "#     Y = tf.one_hot(Y, 10)\n",
    "    Xt = np.transpose(X, [1, 0, 2])\n",
    "#     print(Xt.shape)\n",
    "#     break\n",
    "\n",
    "    caches, states = LSTM_Cell(Xt)\n",
    "    c, h = states[-1]\n",
    "        \n",
    "    out = np.dot(h, wy) + by\n",
    "    pred = softmax(out)\n",
    "    entropy = cross_entropy(pred, Y)\n",
    "    \n",
    "    # Backpropagation Through Time\n",
    "    dout = pred - Y\n",
    "    dwy = np.dot(h.T, dout)\n",
    "    dby = np.sum(dout, axis=0)\n",
    "    \n",
    "    dc_next = np.zeros_like(c)\n",
    "    dh_next = np.zeros_like(h)\n",
    "    \n",
    "    for t in range(Xt.shape[0]):\n",
    "        c, h = states[-t-1]\n",
    "        c_prev, h_prev = states[-t-2]\n",
    "\n",
    "        x, hf, hi, ho, hc = caches[-t-1]\n",
    "        \n",
    "        tc = tanh(c)\n",
    "        dh = np.dot(dout, wy.T) + dh_next\n",
    "        \n",
    "        dc = dh * ho * deriv_tanh(tc)\n",
    "        dc = dc + dc_next\n",
    "        \n",
    "        dho = dh * tc \n",
    "        dho = dho * deriv_sigmoid(ho)\n",
    "        \n",
    "        dhf = dc * c_prev \n",
    "        dhf = dhf * deriv_sigmoid(hf)\n",
    "        \n",
    "        dhi = dc * hc \n",
    "        dhi = dhi * deriv_sigmoid(hi)\n",
    "        \n",
    "        dhc = dc * hi \n",
    "        dhc = dhc * deriv_tanh(hc)\n",
    "        \n",
    "        dwf += np.dot(x.T, dhf)\n",
    "        dbf += np.sum(dhf, axis=0)\n",
    "        dXf = np.dot(dhf, wf.T)\n",
    "        \n",
    "        dwi += np.dot(x.T, dhi)\n",
    "        dbi += np.sum(dhi, axis=0)\n",
    "        dXi = np.dot(dhi, wi.T)\n",
    "        \n",
    "        dwo += np.dot(x.T, dho)\n",
    "        dbo += np.sum(dho, axis=0)\n",
    "        dXo = np.dot(dho, wo.T)\n",
    "        \n",
    "        dwc += np.dot(x.T, dhc)\n",
    "        dbc += np.sum(dhc, axis=0)\n",
    "        dXc = np.dot(dhc, wc.T)\n",
    "\n",
    "        dX = dXf + dXi + dXo + dXc\n",
    "        \n",
    "        dc_next = hf * dc\n",
    "        dh_next = dX[:, -HIDDEN:]\n",
    "        \n",
    "    # Update weights\n",
    "    wf -= ALPHA * dwf\n",
    "    wi -= ALPHA * dwi\n",
    "    wc -= ALPHA * dwc\n",
    "    wo -= ALPHA * dwo\n",
    "    wy -= ALPHA * dwy\n",
    "    \n",
    "    bf -= ALPHA * dbf\n",
    "    bi -= ALPHA * dbi\n",
    "    bc -= ALPHA * dbc\n",
    "    bo -= ALPHA * dbo\n",
    "    by -= ALPHA * dby\n",
    "    \n",
    "    # Initialize delta values\n",
    "    dwf *= 0\n",
    "    dwi *= 0\n",
    "    dwc *= 0\n",
    "    dwo *= 0\n",
    "    dwy *= 0\n",
    "    \n",
    "    dbf *= 0\n",
    "    dbi *= 0\n",
    "    dbc *= 0\n",
    "    dbo *= 0\n",
    "    dby *= 0\n",
    "    \n",
    "    # Log training data\n",
    "    if i % PLOT_ITER == 0:\n",
    "        errors.append(np.sum(entropy))\n",
    "    \n",
    "    if i % LOG_ITER == 0:\n",
    "        print('iter', i)\n",
    "        print('entropy', np.sum(entropy))\n",
    "        print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(train_x))\n",
    "img = train_x[i]\n",
    "img = np.reshape(img, [28, 28])\n",
    "\n",
    "pred = predict(img)\n",
    "print('prediction :', pred)\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
